{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "\n",
    "import ddsp\n",
    "from ddsp.training import (data, decoders, encoders, models, preprocessing, \n",
    "                           train_util, trainers)\n",
    "from ddsp.colab.colab_utils import play, specplot, DEFAULT_SAMPLE_RATE\n",
    "import gin\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from kymatio.tensorflow import Scattering1D\n",
    "\n",
    "sample_rate = DEFAULT_SAMPLE_RATE  # 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio = '/scratch/hh2263/drum_data_ver2/train/'\n",
    "TRAIN_TFRECORD = '/scratch/hh2263/drum_data_ver2/tf_dataset/train.tfrecord'\n",
    "#pkl_dir = '/scratch/hh2263/drum_data_ver2/drumv2_sc-pkl/' #ignore pkl files for now.\n",
    "\n",
    "#run this first to create a tfrecord formatted dataset on the wav2shape folder\n",
    "gin_string = \"\"\"\n",
    "\n",
    "!ddsp_prepare_tfrecord \\\n",
    "--input_audio_filepatterns=/scratch/hh2263/drum_data_ver2/train/*wav \\\n",
    "--output_tfrecord_path= $TRAIN_TFRECORD \\\n",
    "--num_shards=10 \\ac\n",
    "--alsologtostderr\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#could make a generator\n",
    "\n",
    "data_provider = data.FTMProvider(split='test')\n",
    "dataset = data_provider.get_batch(batch_size=1, shuffle=False).take(1).repeat()\n",
    "batch = next(iter(dataset))\n",
    "audio = batch['audio']\n",
    "n_samples = audio.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build model\n",
    "\n",
    "audio->wav2shape encoder (compute scattering, log scale it, compute through the network and yields a 5-d vector theta) -> no decoder -> FTM processor (takes a 5-d vector and synthesize the sound) -> loss: spectral loss of the resulting audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "strategy = train_util.get_strategy() #Get a distribution strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessor as scattering transform\n",
    "#users should pass their own instantiation of kymatio \n",
    "\n",
    "#parameters of scattering\n",
    "J=8\n",
    "shape=(2**15,)\n",
    "Q=1\n",
    "order=2\n",
    "scattering = Scattering1D(J=J,shape=shape,Q=Q,max_order=order)\n",
    "\n",
    "preprocessor = preprocessing.ScatteringPreprocessor(scattering=scattering, eps=1e-3)\n",
    "\n",
    "#encoder is wav2shape or some FC structure - need to output estimates of p_x,p_y,w11,tau11,p,D,alpha\n",
    "encoder = encoders.wav2shapeEncoder(k_size=8,\n",
    "                                   nchan_out=16,\n",
    "                                   input_keys = ('scattering_scaled'), # from preprocessor\n",
    "                                   output_splits=(('position_x',1),\n",
    "                                                  ('position_y',1),\n",
    "                                                  ('w_est', 1),\n",
    "                                                  ('tau_est', 1),\n",
    "                                                  ('p_est', 1),\n",
    "                                                  ('D_est',1),\n",
    "                                                  ('alpha',1)),\n",
    "                                   name='wav2shape_encoder')\n",
    "\n",
    "\n",
    "decoder = None\n",
    "\n",
    "# Create Processors.\n",
    "\n",
    "ftm = ddsp.ftm.FTM(n_samples=2**15,\n",
    "                    sample_rate=sample_rate,\n",
    "                   mode=20,\n",
    "                  name='ftm')\n",
    "\n",
    "# Create ProcessorGroup.\n",
    "\n",
    "dag = [(ftm,['position_x','position_y','w_est','tau_est','p_est','D_est','alpha_est'])]\n",
    "\n",
    "processor_group = ddsp.processors.ProcessorGroup(dag=dag,\n",
    "                                                 name='ftm_processor')\n",
    "\n",
    "\n",
    "# Loss_functions\n",
    "spectral_loss = ddsp.losses.SpectralLoss(loss_type='L1',\n",
    "                                         mag_weight=1.0,\n",
    "                                         logmag_weight=1.0)\n",
    "\n",
    "with strategy.scope():\n",
    "    # Put it together in a model.\n",
    "    model = models.Autoencoder(preprocessor=preprocessor,\n",
    "                             encoder=encoder,\n",
    "                             decoder=None,\n",
    "                             processor_group=processor_group,\n",
    "                             losses=[spectral_loss])\n",
    "    trainer = trainers.Trainer(model, strategy, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gin_string = \"\"\"\n",
    "import ddsp\n",
    "import ddsp.training\n",
    "\n",
    "# Preprocessor\n",
    "models.Autoencoder.preprocessor = @preprocessing.ScatteringPreprocessor()\n",
    "preprocessing.DefaultPreprocessor.eps = 1e-3\n",
    "\n",
    "\n",
    "# Encoder\n",
    "models.Autoencoder.encoder = @encoders.wav2shapeEncoder()\n",
    "\n",
    "encoders.wav2shapeEncoder.k_size=8\n",
    "encoders.wav2shapeEncoder.nchan_out=16\n",
    "encoders.wav2shapeEncoder.activation='linear'\n",
    "encoders.wav2shapeEncoder.input_keys=('scattering_scaled')\n",
    "encoders.wav2shapeEncoder.output_splits = (('theta',5))\n",
    "encoders.wav2shapeEncoder.name='wav2shape_decoder'\n",
    "\n",
    "# Decoder\n",
    "models.Autoencoder.decoder = None\n",
    "\n",
    "\n",
    "# ProcessorGroup\n",
    "models.Autoencoder.processor_group = @processors.ProcessorGroup()\n",
    "\n",
    "processors.ProcessorGroup.dag = [\n",
    "  (@additive/synths.Additive(),\n",
    "    ['amps', 'harmonic_distribution', 'f0_hz']),\n",
    "  (@noise/synths.FilteredNoise(),\n",
    "    ['noise_magnitudes']),\n",
    "  (@add/processors.Add(),\n",
    "    ['noise/signal', 'additive/signal']),\n",
    "]\n",
    "\n",
    "\n",
    "# FTM Synthesizer\n",
    "ftm/ftm.FTM.n_samples = 2**15\n",
    "ftm/ftm.FTM.sample_rate=16000\n",
    "\n",
    "\n",
    "# Additive Synthesizer\n",
    "additive/synths.Additive.name = 'additive'\n",
    "additive/synths.Additive.n_samples = 64000\n",
    "additive/synths.Additive.scale_fn = @core.exp_sigmoid\n",
    "\n",
    "# Filtered Noise Synthesizer\n",
    "noise/synths.FilteredNoise.name = 'noise'\n",
    "noise/synths.FilteredNoise.n_samples = 64000\n",
    "noise/synths.FilteredNoise.window_size = 0\n",
    "noise/synths.FilteredNoise.scale_fn = @core.exp_sigmoid\n",
    "noise/synths.FilteredNoise.initial_bias = -10.0\n",
    "\n",
    "# Add\n",
    "add/processors.Add.name = 'add'\n",
    "\n",
    "models.Autoencoder.losses = [\n",
    "    @losses.SpectralLoss(),\n",
    "]\n",
    "losses.SpectralLoss.loss_type = 'L1'\n",
    "losses.SpectralLoss.mag_weight = 1.0\n",
    "losses.SpectralLoss.logmag_weight = 1.0\n",
    "\"\"\"\n",
    "\n",
    "with gin.unlock_config():\n",
    "  gin.parse_config(gin_string)\n",
    "\n",
    "with strategy.scope():\n",
    "  # Autoencoder arguments are filled by gin.\n",
    "  model = ddsp.training.models.Autoencoder()\n",
    "  trainer = trainers.Trainer(model, strategy, learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Build model, easiest to just run forward pass.\n",
    "dataset = trainer.distribute_dataset(dataset)\n",
    "trainer.build(next(iter(dataset)))\n",
    "\n",
    "dataset_iter = iter(dataset)\n",
    "\n",
    "for i in range(300):\n",
    "    losses = trainer.train_step(dataset_iter)\n",
    "    res_str = 'step: {}\\t'.format(i)\n",
    "    for k, v in losses.items():\n",
    "        res_str += '{}: {:.2f}\\t'.format(k, v)\n",
    "    print(res_str)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training script\n",
    "\n",
    "    \n",
    "ddsp_run \\\n",
    "  --mode=train \\\n",
    "  --save_dir=/tmp/$USER-ddsp-0 \\\n",
    "  --gin_file=models/solo_instrument.gin \\ #one gin file for model configuration\n",
    "  --gin_file=datasets/tfrecord.gin \\ #one gin file for dataset configuration\n",
    "  --gin_file=eval/basic_f0_ld.gin \\ #one gin file for evaluation storage??\n",
    "  --gin_param=\"TFRecordProvider.file_pattern='/path/to/dataset_name.tfrecord*'\" \\\n",
    "  --gin_param=\"batch_size=16\" \\\n",
    "  --alsologtostderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation script\n",
    "ddsp_run \\\n",
    "  --mode=eval \\\n",
    "  --save_dir=/tmp/$USER-ddsp-0 \\\n",
    "  --gin_file=dataset/nsynth.gin \\\n",
    "  --gin_file=eval/basic_f0_ld.gin \\\n",
    "  --alsologtostderr\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
