{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NpJd3dlOCStH"
      },
      "source": [
        "\u003ca href=\"https://colab.research.google.com/github/magenta/ddsp/blob/master/ddsp/colab/demos/train_autoencoder.ipynb\" target=\"_parent\"\u003e\u003cimg src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/\u003e\u003c/a\u003e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hMqWDc_m6rUC"
      },
      "source": [
        "\n",
        "##### Copyright 2020 Google LLC.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VNhgka4UKNjf"
      },
      "outputs": [],
      "source": [
        "# Copyright 2020 Google LLC. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SpXo6phTiOQM"
      },
      "source": [
        "# Train a DDSP Auteoncoder on GPU\n",
        "\n",
        "This notebook demonstrates how to install the DDSP library and train it for synthesis based on your own data using our command-line scripts. If run inside of Colab, it will automatically use a free Google Cloud GPU.\n",
        "\n",
        "At the end, you'll have a custom-trained checkpoint that you can download to use with the [DDSP Timbre Tranfer Colab](https://colab.research.google.com/github/magenta/ddsp/blob/master/ddsp/colab/colab/demos/ddsp_timbre_transfer.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wXjcauVRB48S"
      },
      "source": [
        "**Note that we prefix bash commands with a `!` inside of Colab, but you would leave them out if running directly in a terminal.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vn7CQ4GQizHy"
      },
      "source": [
        "## Install Dependencies\n",
        "\n",
        "First we install the required dependencies with `pip`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "cellView": "both",
        "colab": {},
        "colab_type": "code",
        "id": "jKDRJa6jztLT"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install -qU ddsp[data_preparation]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fb4YD8woYD1H"
      },
      "source": [
        "## Prepare Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uNhH7nEbX2db"
      },
      "source": [
        "#### Upload training audio\n",
        "\n",
        "Upload local audio files to use for training your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "itVKEzF6m3rY"
      },
      "outputs": [],
      "source": [
        "from ddsp.colab import colab_utils\n",
        "\n",
        "AUDIO_DIR = 'data/audio'\n",
        "AUDIO_FILEPATTERN = AUDIO_DIR + '/*'\n",
        "!mkdir -p $AUDIO_DIR\n",
        "\n",
        "uploaded_files, _ = colab_utils.upload()\n",
        "for fname in uploaded_files:\n",
        "  fname_nospace = fname.replace(' ', '_')\n",
        "  !mv \"$fname\" $AUDIO_DIR/$fname_nospace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g_XVFoN2YOat"
      },
      "source": [
        "### Preprocess raw audio into TFRecord dataset\n",
        "\n",
        "We need to do some preprocessing on the raw audio you uploaded to get it into the correct format for training. This involves turning the full audio into short (4-second) examples, inferring the pitch with [CREPE](http://github.com/marl/crepe), and computing the loudness. These features will then be stored in a sharded [TFRecord](https://www.tensorflow.org/tutorials/load_data/tfrecord) file for easier loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MsnkAHyHVrCW"
      },
      "outputs": [],
      "source": [
        "TRAIN_TFRECORD = 'data/train.tfrecord'\n",
        "TRAIN_TFRECORD_FILEPATTERN = TRAIN_TFRECORD + '*'\n",
        "\n",
        "!ddsp_prepare_tfrecord \\\n",
        "  --input_audio_filepatterns=$AUDIO_FILEPATTERN \\\n",
        "  --output_tfrecord_path=$TRAIN_TFRECORD \\\n",
        "  --num_shards=10 \\\n",
        "  --alsologtostderr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nIsq0HrzbOF7"
      },
      "source": [
        "Let's load the dataset in the `ddsp` library and have a look at one of the examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dA-FOmRgYdpZ"
      },
      "outputs": [],
      "source": [
        "from ddsp.colab import colab_utils\n",
        "import ddsp.training\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "data_provider = ddsp.training.data.TFRecordProvider(TRAIN_TFRECORD_FILEPATTERN)\n",
        "dataset = data_provider.get_dataset(shuffle=False)\n",
        "ex = next(iter(dataset))\n",
        "\n",
        "colab_utils.specplot(ex['audio'])\n",
        "colab_utils.play(ex['audio'])\n",
        "\n",
        "f, ax = plt.subplots(3, 1, figsize=(14, 4))\n",
        "x = np.linspace(0, 4.0, 1000)\n",
        "ax[0].set_ylabel('loudness_db')\n",
        "ax[0].plot(x, ex['loudness_db'])\n",
        "ax[1].set_ylabel('F0_Hz')\n",
        "ax[1].set_xlabel('seconds')\n",
        "ax[1].plot(x, ex['f0_hz'])\n",
        "ax[2].set_ylabel('F0_confidence')\n",
        "ax[2].set_xlabel('seconds')\n",
        "ax[2].plot(x, ex['f0_confidence'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9gvXBa7PbuyY"
      },
      "source": [
        "## Train Model\n",
        "\n",
        "We will now train a \"solo instrument\" model. This means the model is conditioned only on the fundamental frequency (f0) and loudness with no instrument ID or latent timbre feature. If you uploaded audio of multiple instruemnts, the neural network you train will attempt to model all timbres, but will likely associate certain timbres with different f0 and loudness conditions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YpwQkSIKjEMZ"
      },
      "source": [
        "First, let's start up a [TensorBoard](https://www.tensorflow.org/tensorboard) to monitor our loss as training proceeds. \n",
        "\n",
        "Initially, TensorBoard will report `No dashboards are active for the current data set.`, but once training begins, the dashboards should appear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "u2lx7yJneUXT"
      },
      "outputs": [],
      "source": [
        "MODEL_DIR = '/content/models/ddsp-solo-instrument'\n",
        "!mkdir -p $MODEL_DIR\n",
        "%reload_ext tensorboard\n",
        "import tensorboard as tb\n",
        "tb.notebook.start('--logdir ' + MODEL_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fT-8Koyvj46w"
      },
      "source": [
        "We will now begin training. \n",
        "\n",
        "Note that we specify [gin configuration](https://github.com/google/gin-config) files for the both the model architecture ([solo_instrument.gin](TODO)) and the dataset ([tfrecord.gin](TODO)), which are both predefined in the library. You could also create your own. We then override some of the spefic params for `batch_size` (which is defined in in the model gin file) and the tfrecord path (which is defined in the dataset file). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "poKO-mZEGYXZ"
      },
      "outputs": [],
      "source": [
        "!ddsp_run \\\n",
        "  --mode=train \\\n",
        "  --alsologtostderr \\\n",
        "  --model_dir=$MODEL_DIR \\\n",
        "  --num_train_steps=1000 \\\n",
        "  --gin_file=models/solo_instrument.gin \\\n",
        "  --gin_file=datasets/tfrecord.gin \\\n",
        "  --gin_param=\"TFRecordProvider.file_pattern='$TRAIN_TFRECORD_FILEPATTERN'\" \\\n",
        "  --gin_param=batch_size=16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZXM2ynLQ2Wl3"
      },
      "source": [
        "## Download Checkpoint\n",
        "\n",
        "Below you can download the final checkpoint. You are now ready to use it in the [DDSP Timbre Tranfer Colab](TODO)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2WDiCyXP0tNE"
      },
      "outputs": [],
      "source": [
        "from ddsp.colab import colab_utils\n",
        "import tensorflow as tf\n",
        "\n",
        "CHECKPOINT_ZIP = 'my_solo_instrument.zip'\n",
        "latest_checkpoint = tf.train.latest_checkpoint(MODEL_DIR)\n",
        "!zip $CHECKPOINT_ZIP $latest_checkpoint* $MODEL_DIR/operative_config-0.gin\n",
        "colab_utils.download(CHECKPOINT_ZIP)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hMqWDc_m6rUC"
      ],
      "name": "train_autoencoder.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
